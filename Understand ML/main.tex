\input{../settings}
\begin{document}

\lhead{Understand Machine Learing} 
\rhead{QSnake Edition} 
\cfoot{\thepage} %\ of \pageref{LastPage}}

\section*{Chapter2: A Gentle Start}
This chapter is talking about a general model of machine learning and commin error.

\subsection*{2.1 Formal Model} $ $\\

\textbf{$\bullet$ The learner's input}
	\begin{enumerate}
		\item[$\cdot$] \textbf{Domain set:} An arbitrary set, $\chi$. This is the set of objects that we may wish to label.
		\item[$\cdot$] \textbf{Label set:} The Answer of the Domain set, usually $\sett{0,1}$ or $\sett{-1,+1}$
		\item[$\cdot$] \textbf{Training data:} $S = ((x_1,y_1),\cdots,(x_m,y_m))$ is a sequence of labeled domain points.
	\end{enumerate}


\textbf{$\bullet$ The learner's output}
\begin{enumerate}
	\item[$\cdot$] $h:\chi \rightarrow y,$ a prediction function, also called a predictor, hypothesis, classifier.
	
	Formally, the learner should choose tin advance a set of predictors. This set is called a hypothesis class and is denoted by $H$. Each $h \in H$ is a function mapping from $\chi$ to $y$.
\end{enumerate}


\textbf{$\bullet$ Other assumption for ML}

\begin{enumerate}
	\item[$\cdot$] \textbf{A data-generation model:} We now explain how the training data is generated by som probability distribution. Let us denote that probability distribution over $\chi$ by $D$.
	\item[$\cdot$] \textbf{Measure of Success:} To know is the output is good or not, we define the loss function to check it
	\begin{enumerate}
		\item \textbf{True error:} $L_{D,f}(h) = \mathbb{P}_{x\sim D}[h(x) \neq f(x)] = D(\sett{x ~|~ h(x) \neq f(x)})$
		\item \textbf{Training error:} $L_S(h) = \dfrac{|\sett{i \in m ~|~ h(x_i) \neq y_i} |}{m}$ where $[m] = \sett{1,\cdots,m}$
	\end{enumerate}
	
	\textbf{\color{red} picture here \color{black} (same training error but different true error)}
	
	\item[$\cdot$] Usually, we denote the probability of getting a non-representative sample by $\delta$, and call ($1 - \delta$) the
\textbf{confidence parameter} of our prediction
\end{enumerate}


\subsection*{2.2 Improve Model} $ $

\textbf{Empirical Risk Minimization}

The method to proof the model is to minimize the loss function by using training data, i.e. $L(S)$

\textbf{Overfitting}

cause by ERM, the data is too fit the training set

example: $h_s(x) = \begin{cases}
	y_i~\text{if}~\exists~i \in [m]~\text{s.t. } x_i = x\\
	0~\text{otherwise}
\end{cases}$

\subsection*{2.3 The upper bound of $L_{(D,f)}(h_s)$ in finite hypothsis} $ $\\

\textbf{Inductive bias \& finite hypothsis}

a method to avoid overfitting, limit the predictor from predictor set $H$

the following article is too hard, it is proofing the upper bound of error.

\textbf{\color{red} a little hard here :)}

\newpage


\section*{Chapter5: The Bias-Complexity Tradeoff}

First, we can decomposition the error to following terms:

$$L_D(h_s) = \epsilon_{app} + \epsilon_{est} ~\text{ where: } \epsilon_{app} = \min_{h \in H}L_D(h),~\epsilon_{est} = L_D(h_s) - \epsilon_{app}$$


\textbf{Error type}
\begin{enumerate}
	\item[$\cdot$] \textbf{The Approximation Error($\epsilon_{app}$)}
	\item[$\cdot$] \textbf{The Estimation Error($\epsilon_{est}$)}
\end{enumerate}

\textbf{Bias-complexity Tradeoff}













\end{document}